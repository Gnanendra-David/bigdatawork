
CSV file absloute path
/user/bigdatacloudxlab27228/RRK/Listings.csv

scp C:\Users\ralla\OneDrive\Desktop\Listings.csv bigdatacloudxlab27228@f.cloudxlab.com:/home/bigdatacloudxlab27228/RRK




SHELL SCRIPT
---------------

/home/bigdatacloudxlab27228/RRK/Listings.csv
==================
mkdir /home/bigdatacloudxlab27228/RRK
hdfs dfs -mkdir RRK
hdfs dfs -copyFromLocal /home/bigdatacloudxlab27228/RRK/Listings.csv /user/bigdatacloudxlab27228/RRK/
hive -f /home/bigdatacloudxlab27228/RRK/RRK_hive.hql
spark-submit /home/bigdatacloudxlab27228/RRK/RRK_spark.py
sh /home/bigdatacloudxlab27228/RRK/RRK_sqoop.sh
----------------------------------------
RRK_hive.hql file
---------------------
create external table if not exists list2(
    LISTING_ID STRING,
    NAME STRING,
    HOST_ID STRING,
    HOST_SINCE STRING,
    HOST_LOCATION STRING,
    HOST_RESPONSE_TIME STRING,
    CITY STRING,
    LATITUDE STRING,
    LONGITUDE STRING,
    REVIEW_SCORES_RATING STRING
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
WITH SERDEPROPERTIES ("separatorChar" = ",", "quoteChar" = "\"")
LOCATION '/user/bigdatacloudxlab27228/RRK'
TBLPROPERTIES ("skip.header.line.count"="1");

==============================================

pysparkfile
-----------
RRK_spark.py

import pyspark
import pyspark.sql.functions
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('sparkdf').enableHiveSupport().getOrCreate()
from pyspark.sql.functions import*
df=spark.sql("select * from rrk.list2")
df.show(10)
df1=df.select([when(col(c)=="",None).otherwise(col(c)).alias(c) for c in df.columns])
df1.show(10)
df2=df1.select([when(col(c).isNull(),'N/A').otherwise(col(c)).alias(c) for c in df1.columns])
df2.show(10)
df2.select([count(when(col(c)=="N/A", c)).alias(c) for c in df2.columns]).show()
df2.write.mode('overwrite').parquet('/user/bigdatacloudxlab27228/hdfs_parq3')


=======================================================================

sqoop export \
--connect jdbc:mysql://cxln2:3306/sqoopex \
--username 'sqoopuser' \
--password 'NHkkP876rp' \
--table rrk_list2 \
--export-dir hdfs://cxln1.c.thelab-240901.internal:8020/user/bigdatacloudxlab27228/hdfs_csv \
--input-fields-terminated-by ',' \
--input-lines-terminated-by '\n' \
-m1


SQL Table schema

create table rrk_list2(listing_id varchar(255), name varchar(255), host_id varchar(255), host_since varchar(255), host_location varchar(255),host_response_time varchar(255), city varchar(255), latitude varchar(255), longitude varchar(255), review_scores_rating varchar(255));

